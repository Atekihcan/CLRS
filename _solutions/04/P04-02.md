---
title:       Problem 4-2
published:   2025-11-09 12:00
modified:    2025-11-09 12:00
keywords:    "parameter passing, recurrence, binary search, merge sort"
description: "Throughout this book, we assume that parameter passing during procedure calls takes constant time, even if an N-element array is being passed. This problem examines the implications of three parameter-passing strategies."
---

> ***Parameter-passing costs***
>
> Throughout this book, we assume that parameter passing during procedure calls takes constant time, even if an $$N$$-element array is being passed. This assumption is valid in most systems because a pointer to the array is passed, not the array itself. This problem examines the implications of three parameter-passing strategies:
>
> 1. An array is passed by pointer. Time = $$\Theta(1)$$.
> 2. An array is passed by copying. Time = $$\Theta(N)$$, where $$N$$ is the size of the array.
> 3. An array is passed by copying only the subrange that might be accessed by the called procedure. Time = $$\Theta(q - p + 1)$$ if the subarray $$A[p..q]$$ is passed.

### Part (a): Binary Search

Consider the recursive binary search algorithm for finding a number in a sorted array. Give recurrences for the worst-case running times of binary search when arrays are passed using each of the three methods above.

**Method 1 (Pass by pointer):**

In each recursive call, we only pass pointers, taking $$\Theta(1)$$ time. The recurrence is:

$$T_1(n) = T_1(n/2) + \Theta(1)$$

Using the master theorem with $$a=1, b=2, f(n)=\Theta(1)$$:
- $$n^{\log_b a} = n^0 = 1$$  
- $$f(n) = \Theta(1) = \Theta(n^{\log_b a})$$

**Case 2 applies:** $$T_1(n) = \Theta(\lg n)$$

**Method 2 (Copy entire array):**

Each recursive call copies the entire original array of size $$N$$:

$$T_2(n) = T_2(n/2) + \Theta(N)$$

This gives $$T_2(n) = \Theta(N \lg n)$$

**Method 3 (Copy subrange):**

Each call copies only the relevant subrange of size $$n$$:

$$T_3(n) = T_3(n/2) + \Theta(n)$$

Using the master theorem:
- $$a=1, b=2, f(n)=\Theta(n)$$
- $$n^{\log_b a} = 1$$
- $$f(n) = \Omega(n^{0+1})$$

**Case 3 applies:** $$T_3(n) = \Theta(n)$$

### Part (b): Merge Sort

Redo part (a) for the MERGE-SORT algorithm from Section 2.3.1.

**Method 1 (Pass by pointer):**

$$T_1(n) = 2T_1(n/2) + \Theta(n)$$

**Solution:** $$T_1(n) = \Theta(n \lg n)$$

This is the standard merge sort complexity.

**Method 2 (Copy entire array):**

Each recursive call copies the entire original array of size $$N$$:

$$T_2(n) = 2T_2(n/2) + \Theta(N) + \Theta(n)$$

The $$\Theta(N)$$ term for copying dominates. At each level of recursion, we copy $$2^i$$ subarrays, each of size $$N$$:

- Level 0: $$1 \cdot N$$
- Level 1: $$2 \cdot N$$  
- Level 2: $$4 \cdot N$$
- ...
- Level $$\lg n$$: $$2^{\lg n} \cdot N = n \cdot N$$

Total: $$N(1 + 2 + 4 + ... + n) = N(2n - 1) = \Theta(Nn)$$

**Solution:** $$T_2(n) = \Theta(Nn)$$

**Method 3 (Copy subrange):**

Each call copies its subrange:

$$T_3(n) = 2T_3(n/2) + \Theta(n) + \Theta(n)$$

The first $$\Theta(n)$$ is for copying, the second for merging.

$$T_3(n) = 2T_3(n/2) + \Theta(n)$$

**Solution:** $$T_3(n) = \Theta(n \lg n)$$

{% capture note %}
**Key Insight:** Pass-by-pointer (Method 1) is most efficient for both algorithms. Method 2 (copying entire array) significantly degrades performance, especially for merge sort where it becomes $$\Theta(Nn)$$. Method 3 (copying subrange) provides a middle ground, maintaining $$O(n \lg n)$$ for merge sort but degrading binary search to $$O(n)$$.
{% endcapture %}
{% include aside.html title='Performance Comparison' %}

### Summary Table

| Algorithm | Method 1 (Pointer) | Method 2 (Copy All) | Method 3 (Copy Subrange) |
|-----------|-------------------|---------------------|-------------------------|
| Binary Search | $$\Theta(\lg n)$$ | $$\Theta(N \lg n)$$ | $$\Theta(n)$$ |
| Merge Sort | $$\Theta(n \lg n)$$ | $$\Theta(Nn)$$ | $$\Theta(n \lg n)$$ |
