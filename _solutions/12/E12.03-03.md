---
title:       Exercise 12.3-3
published:   2025-11-16 10:00
modified:    2025-11-16 10:00
keywords:    "binary search tree, sorting, tree sort, running time analysis"
description: "We can sort a given set of n numbers by first building a binary search tree containing these numbers (using TREE-INSERT repeatedly to insert the numbers one by one) and then printing the numbers by an inorder tree walk. What are the worst-case and best-case running times for this sorting algorithm?"
---

> We can sort a given set of $$n$$ numbers by first building a binary search tree containing these numbers (using $$\textsc{Tree-Insert}$$ repeatedly to insert the numbers one by one) and then printing the numbers by an inorder tree walk. What are the worst-case and best-case running times for this sorting algorithm?

This sorting algorithm, often called **tree sort**, has two phases:

1. **Build phase:** Insert $$n$$ numbers into an initially empty BST
2. **Print phase:** Perform an inorder tree walk to output sorted numbers

Let us analyze each phase separately.

### Print Phase (Inorder Tree Walk)

By Theorem 12.1, an inorder tree walk of an $$n$$-node tree takes $$\Theta(n)$$ time regardless of the tree's structure. This phase always contributes $$\Theta(n)$$ time.

### Build Phase (Repeated Insertion)

The cost of $$n$$ insertions depends on the resulting tree structure, which depends on the order of insertion.

**Worst Case:**

If the input numbers arrive in sorted order (increasing or decreasing), the tree degenerates into a linear chain. For example, inserting $$1, 2, 3, 4, 5$$ in order produces:

```
1
 \
  2
   \
    3
     \
      4
       \
        5
```

In this case:
- Inserting the $$i$$-th element examines $$i$$ nodes (the entire chain so far)
- Total cost: $$\sum_{i=1}^{n} i = \frac{n(n+1)}{2} = \Theta(n^2)$$

**Best Case:**

If the insertions produce a balanced tree (height $$\Theta(\lg n)$$), each insertion takes $$O(\lg n)$$ time. For example, inserting elements in the order $$4, 2, 6, 1, 3, 5, 7$$ produces a balanced tree:

```
      4
     / \
    2   6
   / \ / \
  1  3 5  7
```

{% include ads.html %}

In this case:
- Each insertion takes $$O(\lg n)$$ time
- Total cost: $$n \cdot O(\lg n) = O(n \lg n)$$

The best case is achieved when elements are inserted in an order that keeps the tree balanced, such as inserting the median first, then recursively inserting medians of left and right halves.

### Total Running Time

Combining both phases:

$$\begin{align*}
\text{Total time} &= \text{Build time} + \text{Print time} \\
&= \text{Build time} + \Theta(n)
\end{align*}$$

**Worst-case total time:** $$\Theta(n^2) + \Theta(n) = \Theta(n^2)$$

This occurs when the input is already sorted (or reverse sorted), producing a completely unbalanced tree.

**Best-case total time:** $$O(n \lg n) + \Theta(n) = O(n \lg n)$$

This occurs when insertions produce a balanced tree (height $$\Theta(\lg n)$$).

### Comparison with Other Sorting Algorithms

- **Merge sort, heap sort:** $$\Theta(n \lg n)$$ worst-case (optimal for comparison-based sorting)
- **Quicksort:** $$\Theta(n \lg n)$$ average-case, $$\Theta(n^2)$$ worst-case
- **Tree sort:** $$O(n \lg n)$$ best-case, $$\Theta(n^2)$$ worst-case

Tree sort has the same asymptotic behavior as quicksort: good on random data, poor on sorted data. In fact, there is a deep connection between tree sort and quicksort (see Problem 12-3).

{% capture note %}
To avoid the worst-case behavior of tree sort, we can:

1. **Randomize the input** before insertion (similar to randomized quicksort)
2. **Use balanced BST variants** like red-black trees or AVL trees, which guarantee $$O(\lg n)$$ height and thus $$O(n \lg n)$$ worst-case time
3. **Pre-sort and insert the median first**, recursively building balanced subtrees

With randomization, the expected height of the tree is $$O(\lg n)$$ (Theorem 12.4), giving expected $$O(n \lg n)$$ time.
{% endcapture %}
{% include aside.html title='Avoiding worst-case behavior' %}
